{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存储\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.python_io import TFRecordWriter\n",
    "from tqdm import tqdm\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "output_dir = './data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000it [00:02, 21008.05it/s]\n",
      "10000it [00:00, 20997.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def feature_to_example(img, label):\n",
    "    img = img.tostring() # numpy to string\n",
    "    return tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'img': bytes_feature(img),\n",
    "                'label': int_feature(label)\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def create_tfrecords(output_dir, split='train'):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() # return numpy arrays\n",
    "    x, y = (x_train, y_train) if split=='train' else (x_test, y_test)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, \"mnist_{}.tfrecord\".format(split))\n",
    "    with TFRecordWriter(output_path) as writer:\n",
    "        for (img, label) in tqdm(zip(x, y)):\n",
    "            mnist_example = feature_to_example(img, label)\n",
    "            writer.write(mnist_example.SerializeToString())\n",
    "            \n",
    "create_tfrecords(output_dir, split='train')\n",
    "create_tfrecords(output_dir, split='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example_proto):\n",
    "    feature_dict = {\n",
    "        'img': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    features = tf.parse_single_example(example_proto, features=feature_dict)\n",
    "    \n",
    "    # origional format is uint8\n",
    "    img = tf.decode_raw(features['img'], out_type=tf.uint8)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    \n",
    "    label = features['label']\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    \n",
    "    return (img, label)\n",
    "\n",
    "def load_data(data_dir, split='train', batch_size=64, epochs=1):\n",
    "    data_path = os.path.join(data_dir, \"mnist_{}.tfrecord\".format(split))\n",
    "    dataset = tf.data.TFRecordDataset(data_path)\n",
    "    \n",
    "    if split == 'train':\n",
    "        dataset = dataset.shuffle(60000, reshuffle_each_iteration=True)\n",
    "    else:\n",
    "        dataset = dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
    "        \n",
    "    dataset.repeat(epochs)\n",
    "    \n",
    "    dataset = dataset.map(parse_example)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    \n",
    "    #dataset = dataset.prefetch(1) # not allowed in eager mode\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用TensorFlow过程中可能会遇到的其他数据格式，建议参考PSCAL数据集。该数据集中包含了几乎所有常见的数据形式  \n",
    "[https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py)\n",
    "\n",
    "```python\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "      'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "      'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "  }))\n",
    "  return example\n",
    "```\n",
    "其中`dataset_util`相关代买如下\n",
    "```python\n",
    "def int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value): \n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value): \n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution\n",
    "\n",
    "eager 模式中不需要iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_data(output_dir, split='train')\n",
    "test_ds = load_data(output_dir, split='val')\n",
    "\n",
    "#iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self._input_shape = [-1, 28, 28, 1]\n",
    "        self.conv1 = tf.layers.Conv2D(32, 5,\n",
    "                                  padding='same',\n",
    "                                  activation=tf.nn.relu)\n",
    "        self.max_pool2d = tf.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
    "        self.conv2 = tf.layers.Conv2D(64, 5,\n",
    "                                      padding='same',\n",
    "                                      activation=tf.nn.relu)\n",
    "        self.fc1 = tf.layers.Dense(750, activation=tf.nn.relu)\n",
    "        self.dropout = tf.layers.Dropout(0.5)\n",
    "        self.fc2 = tf.layers.Dense(10)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, self._input_shape)\n",
    "        x = self.max_pool2d(self.conv1(x))\n",
    "        x = self.max_pool2d(self.conv2(x))\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y):\n",
    "    return tf.reduce_mean(\n",
    "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits=model(x), labels=y))\n",
    "\n",
    "def get_accuracy(model, x, y_true):\n",
    "    logits = model(x)\n",
    "    prediction = tf.argmax(logits, 1)\n",
    "    equality = tf.equal(prediction, tf.cast(y_true, tf.int64))\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss: 83.327, train accuracy: 17.19%\n",
      "Iteration 10, loss: 1.934, train accuracy: 53.12%\n",
      "Iteration 20, loss: 0.938, train accuracy: 75.00%\n",
      "Iteration 30, loss: 0.478, train accuracy: 82.81%\n",
      "Iteration 40, loss: 0.215, train accuracy: 93.75%\n",
      "Iteration 50, loss: 0.275, train accuracy: 93.75%\n",
      "Iteration 60, loss: 0.274, train accuracy: 89.06%\n",
      "Iteration 70, loss: 0.441, train accuracy: 84.38%\n",
      "Iteration 80, loss: 0.305, train accuracy: 92.19%\n",
      "Iteration 90, loss: 0.067, train accuracy: 98.44%\n",
      "Iteration 100, loss: 0.187, train accuracy: 93.75%\n",
      "Iteration 110, loss: 0.139, train accuracy: 98.44%\n",
      "Iteration 120, loss: 0.159, train accuracy: 96.88%\n",
      "Iteration 130, loss: 0.183, train accuracy: 93.75%\n",
      "Iteration 140, loss: 0.193, train accuracy: 96.88%\n",
      "Iteration 150, loss: 0.103, train accuracy: 98.44%\n",
      "Iteration 160, loss: 0.111, train accuracy: 95.31%\n",
      "Iteration 170, loss: 0.051, train accuracy: 98.44%\n",
      "Iteration 180, loss: 0.181, train accuracy: 93.75%\n",
      "Iteration 190, loss: 0.158, train accuracy: 96.88%\n",
      "Iteration 200, loss: 0.103, train accuracy: 95.31%\n",
      "Iteration 210, loss: 0.193, train accuracy: 92.19%\n",
      "Iteration 220, loss: 0.134, train accuracy: 98.44%\n",
      "Iteration 230, loss: 0.038, train accuracy: 100.00%\n",
      "Iteration 240, loss: 0.040, train accuracy: 96.88%\n",
      "Iteration 250, loss: 0.034, train accuracy: 98.44%\n",
      "Iteration 260, loss: 0.018, train accuracy: 100.00%\n",
      "Iteration 270, loss: 0.070, train accuracy: 98.44%\n",
      "Iteration 280, loss: 0.101, train accuracy: 96.88%\n",
      "Iteration 290, loss: 0.086, train accuracy: 98.44%\n",
      "Iteration 300, loss: 0.016, train accuracy: 100.00%\n",
      "Iteration 310, loss: 0.043, train accuracy: 98.44%\n",
      "Iteration 320, loss: 0.017, train accuracy: 100.00%\n",
      "Iteration 330, loss: 0.112, train accuracy: 98.44%\n",
      "Iteration 340, loss: 0.035, train accuracy: 98.44%\n",
      "Iteration 350, loss: 0.140, train accuracy: 96.88%\n",
      "Iteration 360, loss: 0.152, train accuracy: 93.75%\n",
      "Iteration 370, loss: 0.078, train accuracy: 98.44%\n",
      "Iteration 380, loss: 0.017, train accuracy: 100.00%\n",
      "Iteration 390, loss: 0.019, train accuracy: 100.00%\n",
      "Iteration 400, loss: 0.030, train accuracy: 98.44%\n",
      "Iteration 410, loss: 0.075, train accuracy: 98.44%\n",
      "Iteration 420, loss: 0.091, train accuracy: 96.88%\n",
      "Iteration 430, loss: 0.054, train accuracy: 98.44%\n",
      "Iteration 440, loss: 0.053, train accuracy: 98.44%\n",
      "Iteration 450, loss: 0.048, train accuracy: 98.44%\n",
      "Iteration 460, loss: 0.193, train accuracy: 93.75%\n",
      "Iteration 470, loss: 0.016, train accuracy: 100.00%\n",
      "Iteration 480, loss: 0.028, train accuracy: 100.00%\n",
      "Iteration 490, loss: 0.021, train accuracy: 100.00%\n",
      "Iteration 500, loss: 0.071, train accuracy: 98.44%\n",
      "Iteration 510, loss: 0.043, train accuracy: 98.44%\n",
      "Iteration 520, loss: 0.057, train accuracy: 98.44%\n",
      "Iteration 530, loss: 0.146, train accuracy: 96.88%\n",
      "Iteration 540, loss: 0.051, train accuracy: 98.44%\n",
      "Iteration 550, loss: 0.012, train accuracy: 100.00%\n",
      "Iteration 560, loss: 0.067, train accuracy: 98.44%\n",
      "Iteration 570, loss: 0.132, train accuracy: 96.88%\n",
      "Iteration 580, loss: 0.110, train accuracy: 96.88%\n",
      "Iteration 590, loss: 0.026, train accuracy: 100.00%\n",
      "Iteration 600, loss: 0.020, train accuracy: 100.00%\n",
      "Iteration 610, loss: 0.048, train accuracy: 96.88%\n",
      "Iteration 620, loss: 0.056, train accuracy: 98.44%\n",
      "Iteration 630, loss: 0.032, train accuracy: 98.44%\n",
      "Iteration 640, loss: 0.041, train accuracy: 98.44%\n",
      "Iteration 650, loss: 0.014, train accuracy: 100.00%\n",
      "Iteration 660, loss: 0.146, train accuracy: 96.88%\n",
      "Iteration 670, loss: 0.232, train accuracy: 93.75%\n",
      "Iteration 680, loss: 0.066, train accuracy: 98.44%\n",
      "Iteration 690, loss: 0.005, train accuracy: 100.00%\n",
      "Iteration 700, loss: 0.009, train accuracy: 100.00%\n",
      "Iteration 710, loss: 0.010, train accuracy: 100.00%\n",
      "Iteration 720, loss: 0.010, train accuracy: 100.00%\n",
      "Iteration 730, loss: 0.052, train accuracy: 96.88%\n",
      "Iteration 740, loss: 0.018, train accuracy: 100.00%\n",
      "Iteration 750, loss: 0.024, train accuracy: 100.00%\n",
      "Iteration 760, loss: 0.077, train accuracy: 98.44%\n",
      "Iteration 770, loss: 0.011, train accuracy: 100.00%\n",
      "Iteration 780, loss: 0.031, train accuracy: 100.00%\n",
      "Iteration 790, loss: 0.035, train accuracy: 98.44%\n",
      "Iteration 800, loss: 0.017, train accuracy: 100.00%\n",
      "Iteration 810, loss: 0.026, train accuracy: 100.00%\n",
      "Iteration 820, loss: 0.017, train accuracy: 100.00%\n",
      "Iteration 830, loss: 0.022, train accuracy: 100.00%\n",
      "Iteration 840, loss: 0.048, train accuracy: 98.44%\n",
      "Iteration 850, loss: 0.029, train accuracy: 100.00%\n",
      "Iteration 860, loss: 0.083, train accuracy: 98.44%\n",
      "Iteration 870, loss: 0.092, train accuracy: 98.44%\n",
      "Iteration 880, loss: 0.025, train accuracy: 100.00%\n",
      "Iteration 890, loss: 0.088, train accuracy: 96.88%\n",
      "Iteration 900, loss: 0.030, train accuracy: 100.00%\n",
      "Iteration 910, loss: 0.022, train accuracy: 100.00%\n",
      "Iteration 920, loss: 0.194, train accuracy: 95.31%\n",
      "Iteration 930, loss: 0.013, train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = MNISTModel()\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "epochs = 1000\n",
    "for (batch, (images, labels)) in enumerate(train_ds):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    \n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "    if batch % 10 == 0:\n",
    "        acc = get_accuracy(model, images, labels).numpy()\n",
    "        print(\"Iteration {}, loss: {:.3f}, train accuracy: {:.2f}%\".format(batch, loss_fn(model, images, labels).numpy(), acc*100))\n",
    "    if batch > epochs:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:100, Average test accuracy: 98.92%\n",
      "Final test accuracy: 98.56%\n"
     ]
    }
   ],
   "source": [
    "avg_acc = 0\n",
    "test_epochs = 20\n",
    "for (batch, (images, labels)) in enumerate(test_ds):\n",
    "    avg_acc += get_accuracy(model, images, labels).numpy()\n",
    "    if batch % 100 == 0 and batch != 0:\n",
    "        print(\"Iteration:{}, Average test accuracy: {:.2f}%\".format(batch, (avg_acc/batch)*100))\n",
    "print(\"Final test accuracy: {:.2f}%\".format(avg_acc/batch * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
